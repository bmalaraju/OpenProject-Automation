{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \u23f1\ufe0f Processing Time Analysis Dashboard\n",
                "\n",
                "**Purpose**: Analyze cycle times, processing durations, and operational efficiency metrics.\n",
                "\n",
                "## Key Metrics\n",
                "- Time to Acknowledge\n",
                "- Time to Submit\n",
                "- Time to Approve\n",
                "- Total Cycle Time\n",
                "- Bottleneck identification\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Install required packages\n",
                "!pip install pandas openpyxl plotly seaborn matplotlib -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "print(\"\u2705 Libraries loaded successfully!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# File path - update this to match your file location\n",
                "filename = r\"C:\\Users\\bmalaraju\\Documents\\WP-OP Agent\\JIRA-Agent\\11.25.WP Orders_25-11-2025_v01.xlsx\"\n",
                "print(f\"\ud83d\udcc1 Using file: {filename}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Load data\n",
                "df = pd.read_excel(filename, engine='openpyxl')\n",
                "print(f\"\ud83d\udcca Dataset loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
                "print(f\"\ud83d\udcc5 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Column mapping for date fields\n",
                "DATE_COLUMNS = {\n",
                "    'added': 'Added Date',\n",
                "    'acknowledged': 'Acknowledgement Date',\n",
                "    'submitted': 'Submitted Date',\n",
                "    'approved': 'Approved Date',\n",
                "    'cancelled': 'Cancelled Date',\n",
                "    'po_start': 'PO StartDate',\n",
                "    'po_end': 'PO EndDate',\n",
                "    'requested': 'WP Requested Delivery Date',\n",
                "    'readiness': 'WP Readiness Date',\n",
                "    'updated': 'Updated Date'\n",
                "}\n",
                "\n",
                "OTHER_COLUMNS = {\n",
                "    'status': 'WP Order Status',\n",
                "    'product': 'Product',\n",
                "    'customer': 'Customer',\n",
                "    'order_id': 'WP Order ID',\n",
                "    'employee': 'Employee Name',\n",
                "    'std': 'STD'\n",
                "}\n",
                "\n",
                "# Check availability\n",
                "available_dates = {k: v for k, v in DATE_COLUMNS.items() if v in df.columns}\n",
                "print(f\"\u2705 Available date columns: {len(available_dates)} of {len(DATE_COLUMNS)}\")\n",
                "for k, v in available_dates.items():\n",
                "    print(f\"   - {v}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Prepare analysis dataframe with parsed dates\n",
                "analysis_df = df.copy()\n",
                "\n",
                "# Helper to strip timezone from dates\n",
                "def parse_date(series):\n",
                "    dt = pd.to_datetime(series, errors='coerce')\n",
                "    if dt.dt.tz is not None:\n",
                "        dt = dt.dt.tz_localize(None)\n",
                "    return dt\n",
                "\n",
                "# Parse all date columns with timezone normalization\n",
                "for key, col in DATE_COLUMNS.items():\n",
                "    if col in analysis_df.columns:\n",
                "        analysis_df[f'{key}_date'] = parse_date(analysis_df[col])\n",
                "    else:\n",
                "        analysis_df[f'{key}_date'] = pd.NaT\n",
                "\n",
                "# Parse STD (Standard Time in Days)\n",
                "std_col = OTHER_COLUMNS.get('std')\n",
                "if std_col and std_col in analysis_df.columns:\n",
                "    analysis_df['std_days'] = pd.to_numeric(analysis_df[std_col], errors='coerce').fillna(0)\n",
                "else:\n",
                "    analysis_df['std_days'] = 0\n",
                "\n",
                "print(\"\\n\u2705 Dates parsed successfully!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Calculate time intervals (in days)\n",
                "\n",
                "# Time to Acknowledge: Acknowledged - Added\n",
                "analysis_df['time_to_ack'] = (analysis_df['acknowledged_date'] - analysis_df['added_date']).dt.days\n",
                "\n",
                "# Time to Submit: Submitted - Acknowledged\n",
                "analysis_df['time_to_submit'] = (analysis_df['submitted_date'] - analysis_df['acknowledged_date']).dt.days\n",
                "\n",
                "# Time to Approve: Approved - Submitted\n",
                "analysis_df['time_to_approve'] = (analysis_df['approved_date'] - analysis_df['submitted_date']).dt.days\n",
                "\n",
                "# Total Cycle Time: Approved/Cancelled - Added\n",
                "# Use the latest of approved/cancelled as terminal date\n",
                "analysis_df['terminal_date'] = analysis_df[['approved_date', 'cancelled_date']].max(axis=1)\n",
                "analysis_df['total_cycle_time'] = (analysis_df['terminal_date'] - analysis_df['added_date']).dt.days\n",
                "\n",
                "# PO Duration\n",
                "analysis_df['po_duration'] = (analysis_df['po_end_date'] - analysis_df['po_start_date']).dt.days\n",
                "\n",
                "# STD Variance: Actual - Standard\n",
                "analysis_df['std_variance'] = analysis_df['total_cycle_time'] - analysis_df['std_days']\n",
                "\n",
                "# Clean up negative values (data quality issues)\n",
                "time_cols = ['time_to_ack', 'time_to_submit', 'time_to_approve', 'total_cycle_time', 'po_duration']\n",
                "for col in time_cols:\n",
                "    analysis_df.loc[analysis_df[col] < 0, col] = np.nan\n",
                "\n",
                "print(\"\u2705 Time intervals calculated!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Processing Time Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Calculate summary statistics\n",
                "def calc_stats(series):\n",
                "    clean = series.dropna()\n",
                "    if len(clean) == 0:\n",
                "        return {'count': 0, 'mean': 0, 'median': 0, 'p25': 0, 'p75': 0, 'max': 0}\n",
                "    return {\n",
                "        'count': len(clean),\n",
                "        'mean': clean.mean(),\n",
                "        'median': clean.median(),\n",
                "        'p25': clean.quantile(0.25),\n",
                "        'p75': clean.quantile(0.75),\n",
                "        'max': clean.max()\n",
                "    }\n",
                "\n",
                "time_metrics = {\n",
                "    'Time to Acknowledge': calc_stats(analysis_df['time_to_ack']),\n",
                "    'Time to Submit': calc_stats(analysis_df['time_to_submit']),\n",
                "    'Time to Approve': calc_stats(analysis_df['time_to_approve']),\n",
                "    'Total Cycle Time': calc_stats(analysis_df['total_cycle_time']),\n",
                "    'PO Duration': calc_stats(analysis_df['po_duration'])\n",
                "}\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"\u23f1\ufe0f PROCESSING TIME SUMMARY (in days)\")\n",
                "print(\"=\"*80)\n",
                "print(f\"{'Metric':<25} {'Count':>8} {'Mean':>8} {'Median':>8} {'P25':>8} {'P75':>8} {'Max':>8}\")\n",
                "print(\"-\"*80)\n",
                "for name, stats in time_metrics.items():\n",
                "    if stats['count'] > 0:\n",
                "        print(f\"{name:<25} {stats['count']:>8,} {stats['mean']:>8.1f} {stats['median']:>8.1f} {stats['p25']:>8.1f} {stats['p75']:>8.1f} {stats['max']:>8.0f}\")\n",
                "print(\"=\"*80)"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# KPI Indicators for average times\n",
                "ack_mean = time_metrics['Time to Acknowledge']['mean']\n",
                "submit_mean = time_metrics['Time to Submit']['mean']\n",
                "approve_mean = time_metrics['Time to Approve']['mean']\n",
                "cycle_mean = time_metrics['Total Cycle Time']['mean']\n",
                "\n",
                "fig = make_subplots(\n",
                "    rows=1, cols=4,\n",
                "    specs=[[{'type': 'indicator'}]*4],\n",
                "    subplot_titles=['Avg Acknowledge', 'Avg Submit', 'Avg Approve', 'Avg Total Cycle']\n",
                ")\n",
                "\n",
                "fig.add_trace(go.Indicator(\n",
                "    mode=\"number\",\n",
                "    value=ack_mean,\n",
                "    number={'suffix': ' days', 'font': {'size': 30, 'color': '#3498DB'}}\n",
                "), row=1, col=1)\n",
                "\n",
                "fig.add_trace(go.Indicator(\n",
                "    mode=\"number\",\n",
                "    value=submit_mean,\n",
                "    number={'suffix': ' days', 'font': {'size': 30, 'color': '#2ECC71'}}\n",
                "), row=1, col=2)\n",
                "\n",
                "fig.add_trace(go.Indicator(\n",
                "    mode=\"number\",\n",
                "    value=approve_mean,\n",
                "    number={'suffix': ' days', 'font': {'size': 30, 'color': '#E67E22'}}\n",
                "), row=1, col=3)\n",
                "\n",
                "fig.add_trace(go.Indicator(\n",
                "    mode=\"number\",\n",
                "    value=cycle_mean,\n",
                "    number={'suffix': ' days', 'font': {'size': 30, 'color': '#9B59B6'}}\n",
                "), row=1, col=4)\n",
                "\n",
                "fig.update_layout(height=200, title={'text': 'Average Processing Times', 'x': 0.5})\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Stage-by-Stage Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Waterfall: Average time breakdown\n",
                "stages = ['Time to Acknowledge', 'Time to Submit', 'Time to Approve']\n",
                "avg_times = [ack_mean, submit_mean, approve_mean]\n",
                "\n",
                "fig = go.Figure(go.Waterfall(\n",
                "    name=\"Processing Time\",\n",
                "    orientation=\"v\",\n",
                "    measure=['relative', 'relative', 'relative', 'total'],\n",
                "    x=stages + ['Total (Sum)'],\n",
                "    y=avg_times + [0],\n",
                "    connector={\"line\": {\"color\": \"rgb(63, 63, 63)\"}},\n",
                "    text=[f\"{t:.1f}d\" for t in avg_times] + [f\"{sum(avg_times):.1f}d\"],\n",
                "    textposition=\"outside\",\n",
                "    increasing={\"marker\": {\"color\": \"#3498DB\"}},\n",
                "    totals={\"marker\": {\"color\": \"#9B59B6\"}}\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'Cumulative Processing Time Breakdown', 'x': 0.5, 'font': {'size': 20}},\n",
                "    yaxis_title='Days',\n",
                "    height=400\n",
                ")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Box plots for time distributions\n",
                "fig = go.Figure()\n",
                "\n",
                "time_data = [\n",
                "    ('Time to Ack', analysis_df['time_to_ack'].dropna(), '#3498DB'),\n",
                "    ('Time to Submit', analysis_df['time_to_submit'].dropna(), '#2ECC71'),\n",
                "    ('Time to Approve', analysis_df['time_to_approve'].dropna(), '#E67E22'),\n",
                "    ('Total Cycle', analysis_df['total_cycle_time'].dropna(), '#9B59B6')\n",
                "]\n",
                "\n",
                "for name, data, color in time_data:\n",
                "    if len(data) > 0:\n",
                "        # Cap at 99th percentile for visualization\n",
                "        cap = data.quantile(0.99)\n",
                "        fig.add_trace(go.Box(\n",
                "            y=data[data <= cap],\n",
                "            name=name,\n",
                "            marker_color=color,\n",
                "            boxmean=True\n",
                "        ))\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'Processing Time Distribution (Box Plots)', 'x': 0.5, 'font': {'size': 20}},\n",
                "    yaxis_title='Days',\n",
                "    height=450,\n",
                "    showlegend=False\n",
                ")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Cycle Time Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Histogram: Total cycle time distribution\n",
                "cycle_data = analysis_df['total_cycle_time'].dropna()\n",
                "\n",
                "if len(cycle_data) > 0:\n",
                "    # Cap at 99th percentile\n",
                "    cap = cycle_data.quantile(0.99)\n",
                "    cycle_capped = cycle_data[cycle_data <= cap]\n",
                "    \n",
                "    fig = go.Figure(data=[go.Histogram(\n",
                "        x=cycle_capped,\n",
                "        nbinsx=30,\n",
                "        marker_color='#9B59B6'\n",
                "    )])\n",
                "    \n",
                "    fig.update_layout(\n",
                "        title={'text': 'Total Cycle Time Distribution', 'x': 0.5, 'font': {'size': 20}},\n",
                "        xaxis_title='Days',\n",
                "        yaxis_title='Number of Orders',\n",
                "        height=400\n",
                "    )\n",
                "    \n",
                "    # Add mean and median lines\n",
                "    mean_val = cycle_data.mean()\n",
                "    median_val = cycle_data.median()\n",
                "    \n",
                "    fig.add_vline(x=mean_val, line_dash=\"dash\", line_color=\"red\",\n",
                "                  annotation_text=f\"Mean: {mean_val:.1f}d\")\n",
                "    fig.add_vline(x=median_val, line_dash=\"dash\", line_color=\"green\",\n",
                "                  annotation_text=f\"Median: {median_val:.1f}d\")\n",
                "    \n",
                "    fig.show()\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f No cycle time data available\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Processing Time by Product"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Average processing time by product\n",
                "product_col = OTHER_COLUMNS.get('product')\n",
                "\n",
                "if product_col and product_col in analysis_df.columns:\n",
                "    product_times = analysis_df.groupby(product_col).agg(\n",
                "        count=('total_cycle_time', 'count'),\n",
                "        avg_cycle=('total_cycle_time', 'mean'),\n",
                "        avg_ack=('time_to_ack', 'mean'),\n",
                "        avg_submit=('time_to_submit', 'mean'),\n",
                "        avg_approve=('time_to_approve', 'mean')\n",
                "    ).reset_index()\n",
                "    \n",
                "    # Filter to products with enough data\n",
                "    product_times = product_times[product_times['count'] >= 5]\n",
                "    product_times = product_times.nlargest(15, 'avg_cycle')\n",
                "    product_times = product_times.sort_values('avg_cycle', ascending=True)\n",
                "    \n",
                "    fig = go.Figure(data=[go.Bar(\n",
                "        y=product_times[product_col],\n",
                "        x=product_times['avg_cycle'],\n",
                "        orientation='h',\n",
                "        marker_color='#9B59B6',\n",
                "        text=product_times['avg_cycle'].apply(lambda x: f'{x:.1f}d'),\n",
                "        textposition='outside'\n",
                "    )])\n",
                "    \n",
                "    fig.update_layout(\n",
                "        title={'text': 'Average Cycle Time by Product (Top 15 Slowest)', 'x': 0.5, 'font': {'size': 20}},\n",
                "        xaxis_title='Average Days',\n",
                "        yaxis_title='Product',\n",
                "        height=500,\n",
                "        margin={'l': 200}\n",
                "    )\n",
                "    \n",
                "    fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Stacked bar: Time breakdown by product\n",
                "if product_col and product_col in analysis_df.columns and len(product_times) > 0:\n",
                "    top_products = product_times.tail(10)  # Top 10 by cycle time\n",
                "    \n",
                "    fig = go.Figure()\n",
                "    \n",
                "    fig.add_trace(go.Bar(\n",
                "        y=top_products[product_col],\n",
                "        x=top_products['avg_ack'].fillna(0),\n",
                "        name='Acknowledge',\n",
                "        orientation='h',\n",
                "        marker_color='#3498DB'\n",
                "    ))\n",
                "    \n",
                "    fig.add_trace(go.Bar(\n",
                "        y=top_products[product_col],\n",
                "        x=top_products['avg_submit'].fillna(0),\n",
                "        name='Submit',\n",
                "        orientation='h',\n",
                "        marker_color='#2ECC71'\n",
                "    ))\n",
                "    \n",
                "    fig.add_trace(go.Bar(\n",
                "        y=top_products[product_col],\n",
                "        x=top_products['avg_approve'].fillna(0),\n",
                "        name='Approve',\n",
                "        orientation='h',\n",
                "        marker_color='#E67E22'\n",
                "    ))\n",
                "    \n",
                "    fig.update_layout(\n",
                "        title={'text': 'Processing Time Breakdown by Product', 'x': 0.5, 'font': {'size': 20}},\n",
                "        barmode='stack',\n",
                "        xaxis_title='Days',\n",
                "        yaxis_title='Product',\n",
                "        height=450,\n",
                "        margin={'l': 200},\n",
                "        legend={'orientation': 'h', 'y': 1.1}\n",
                "    )\n",
                "    \n",
                "    fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Bottleneck Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Identify bottleneck stage\n",
                "stage_means = {\n",
                "    'Acknowledge': ack_mean,\n",
                "    'Submit': submit_mean,\n",
                "    'Approve': approve_mean\n",
                "}\n",
                "\n",
                "bottleneck = max(stage_means, key=stage_means.get)\n",
                "total_avg = sum(stage_means.values())\n",
                "\n",
                "print(\"\\n\ud83d\udd0d BOTTLENECK ANALYSIS\")\n",
                "print(\"=\"*60)\n",
                "for stage, avg_time in sorted(stage_means.items(), key=lambda x: x[1], reverse=True):\n",
                "    pct = (avg_time / total_avg * 100) if total_avg > 0 else 0\n",
                "    indicator = \"\ud83d\udea8\" if stage == bottleneck else \"  \"\n",
                "    print(f\"{indicator} {stage:<20} {avg_time:>8.1f} days ({pct:>5.1f}% of cycle)\")\n",
                "\n",
                "print(f\"\\n\u26a0\ufe0f Bottleneck identified: {bottleneck} stage\")\n",
                "print(f\"   Contributes {stage_means[bottleneck]/total_avg*100:.1f}% of total processing time\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Bottleneck pie chart\n",
                "colors = ['#FF6B6B' if s == bottleneck else '#4ECDC4' for s in stage_means.keys()]\n",
                "\n",
                "fig = go.Figure(data=[go.Pie(\n",
                "    labels=list(stage_means.keys()),\n",
                "    values=list(stage_means.values()),\n",
                "    hole=0.4,\n",
                "    marker_colors=colors,\n",
                "    textinfo='percent+label'\n",
                ")])\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'Time Distribution Across Stages', 'x': 0.5, 'font': {'size': 20}},\n",
                "    annotations=[{'text': f'\ud83d\udea8<br>{bottleneck}', 'x': 0.5, 'y': 0.5, 'font_size': 14, 'showarrow': False}],\n",
                "    height=400\n",
                ")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. STD Variance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# STD (Standard Time) variance analysis\n",
                "std_variance = analysis_df['std_variance'].dropna()\n",
                "\n",
                "if len(std_variance) > 0 and analysis_df['std_days'].sum() > 0:\n",
                "    # Orders exceeding STD\n",
                "    exceeds_std = (std_variance > 0).sum()\n",
                "    within_std = (std_variance <= 0).sum()\n",
                "    \n",
                "    print(\"\\n\ud83d\udcca STD (Standard Time) COMPLIANCE\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"   Orders with STD data: {len(std_variance):,}\")\n",
                "    print(f\"   Within STD:           {within_std:,} ({within_std/len(std_variance)*100:.1f}%)\")\n",
                "    print(f\"   Exceeds STD:          {exceeds_std:,} ({exceeds_std/len(std_variance)*100:.1f}%)\")\n",
                "    print(f\"\\n   Avg Variance:         {std_variance.mean():.1f} days\")\n",
                "    print(f\"   Max Overrun:          {std_variance.max():.0f} days\")\n",
                "    \n",
                "    # Histogram\n",
                "    cap = std_variance.abs().quantile(0.95)\n",
                "    variance_capped = std_variance[(std_variance > -cap) & (std_variance < cap)]\n",
                "    \n",
                "    fig = go.Figure(data=[go.Histogram(\n",
                "        x=variance_capped,\n",
                "        nbinsx=40,\n",
                "        marker_color=np.where(variance_capped > 0, '#FF6B6B', '#4ECDC4').tolist()\n",
                "    )])\n",
                "    \n",
                "    fig.add_vline(x=0, line_color=\"black\", line_width=2, annotation_text=\"On Target\")\n",
                "    \n",
                "    fig.update_layout(\n",
                "        title={'text': 'STD Variance Distribution (Actual - Standard)', 'x': 0.5, 'font': {'size': 20}},\n",
                "        xaxis_title='Variance (Days) - Negative = Early, Positive = Late',\n",
                "        yaxis_title='Count',\n",
                "        height=400\n",
                "    )\n",
                "    \n",
                "    fig.show()\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f No STD data available for variance analysis\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Slowest Orders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Top 20 slowest orders\n",
                "order_col = OTHER_COLUMNS.get('order_id')\n",
                "status_col = OTHER_COLUMNS.get('status')\n",
                "\n",
                "slowest = analysis_df[\n",
                "    analysis_df['total_cycle_time'].notna()\n",
                "].nlargest(20, 'total_cycle_time')\n",
                "\n",
                "cols_to_show = [order_col, product_col, status_col, 'time_to_ack', 'time_to_submit', 'time_to_approve', 'total_cycle_time']\n",
                "cols_to_show = [c for c in cols_to_show if c in slowest.columns or c in slowest.columns]\n",
                "\n",
                "display_cols = [c if c in slowest.columns else None for c in cols_to_show]\n",
                "display_cols = [c for c in display_cols if c]\n",
                "\n",
                "slowest_display = slowest[display_cols].copy()\n",
                "slowest_display.columns = ['Order ID', 'Product', 'Status', 'Ack (d)', 'Submit (d)', 'Approve (d)', 'Total (d)']\n",
                "\n",
                "print(\"\\n\ud83d\udc0c TOP 20 SLOWEST ORDERS\")\n",
                "print(\"=\"*100)\n",
                "print(slowest_display.to_string(index=False))"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Processing Time Trend"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Weekly average cycle time trend\n",
                "trend_df = analysis_df[analysis_df['added_date'].notna() & analysis_df['total_cycle_time'].notna()].copy()\n",
                "trend_df['week'] = trend_df['added_date'].dt.to_period('W').dt.start_time\n",
                "\n",
                "weekly_times = trend_df.groupby('week').agg(\n",
                "    avg_cycle=('total_cycle_time', 'mean'),\n",
                "    count=('total_cycle_time', 'count')\n",
                ").reset_index()\n",
                "\n",
                "# Last 12 weeks\n",
                "weekly_times = weekly_times.tail(12)\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=weekly_times['week'],\n",
                "    y=weekly_times['avg_cycle'],\n",
                "    mode='lines+markers',\n",
                "    name='Avg Cycle Time',\n",
                "    line=dict(color='#9B59B6', width=3)\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'Weekly Average Cycle Time Trend', 'x': 0.5, 'font': {'size': 20}},\n",
                "    xaxis_title='Week',\n",
                "    yaxis_title='Average Days',\n",
                "    height=400\n",
                ")\n",
                "\n",
                "# Add overall mean line\n",
                "overall_mean = analysis_df['total_cycle_time'].mean()\n",
                "fig.add_hline(y=overall_mean, line_dash=\"dash\", line_color=\"gray\",\n",
                "              annotation_text=f\"Overall Avg: {overall_mean:.1f}d\")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Export Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Export to Excel\n",
                "export_filename = f\"processing_time_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
                "\n",
                "with pd.ExcelWriter(export_filename, engine='openpyxl') as writer:\n",
                "    # Summary statistics\n",
                "    summary_rows = []\n",
                "    for name, stats in time_metrics.items():\n",
                "        summary_rows.append({\n",
                "            'Metric': name,\n",
                "            'Count': stats['count'],\n",
                "            'Mean (days)': round(stats['mean'], 1),\n",
                "            'Median (days)': round(stats['median'], 1),\n",
                "            'P25': round(stats['p25'], 1),\n",
                "            'P75': round(stats['p75'], 1),\n",
                "            'Max': round(stats['max'], 0)\n",
                "        })\n",
                "    pd.DataFrame(summary_rows).to_excel(writer, sheet_name='Summary', index=False)\n",
                "    \n",
                "    # By Product\n",
                "    if 'product_times' in dir():\n",
                "        product_times.to_excel(writer, sheet_name='By Product', index=False)\n",
                "    \n",
                "    # Slowest orders\n",
                "    slowest_display.to_excel(writer, sheet_name='Slowest Orders', index=False)\n",
                "\n",
                "print(f\"\\n\u2705 Results exported to: {export_filename}\")\n",
                "# files.download() - uncomment if using Colab\n",
                "# files.download(export_filename)"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## \ud83d\udccb Summary\n",
                "\n",
                "This notebook analyzed processing times and operational efficiency:\n",
                "\n",
                "| Metric | Description |\n",
                "|--------|-------------|\n",
                "| **Time to Acknowledge** | Days from Added to Acknowledged |\n",
                "| **Time to Submit** | Days from Acknowledged to Submitted |\n",
                "| **Time to Approve** | Days from Submitted to Approved |\n",
                "| **Total Cycle Time** | Days from Added to Terminal status |\n",
                "| **STD Variance** | Actual cycle time vs Standard time |\n",
                "\n",
                "### Key Insights\n",
                "1. Focus improvements on the bottleneck stage\n",
                "2. Investigate products with long cycle times\n",
                "3. Address orders exceeding STD targets\n",
                "4. Track trend improvements over time"
            ]
        }
    ]
}