{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 07 - WP Orders Change Analysis (Exact Delta Apply Match)\n",
                "\n",
                "This notebook uses the **exact same hash function** as `delta_apply_influx.py`:\n",
                "- Same 17 columns used for hash computation\n",
                "- Same JSON serialization method\n",
                "- Same SHA256 hashing\n",
                "\n",
                "Results should match the delta apply report exactly.\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import hashlib\n",
                "import json\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from typing import List, Any\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "pd.set_option('display.max_columns', 50)\n",
                "pd.set_option('display.max_colwidth', 50)\n",
                "print(\"Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Hash Function (Exact Copy from influx_source.py)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# EXACT hash function from src/wpr_agent/router/tools/influx_source.py\n",
                "# Lines 188-218\n",
                "\n",
                "HASH_COLUMNS = [\n",
                "    \"WP Order ID\",\n",
                "    \"WP Order Status\",\n",
                "    \"WP ID\",\n",
                "    \"WP Name\",\n",
                "    \"WP Quantity\",\n",
                "    \"Employee Name\",\n",
                "    \"STD\",\n",
                "    \"WP Requested Delivery Date\",\n",
                "    \"WP Readiness Date\",\n",
                "    \"PO StartDate\",\n",
                "    \"PO EndDate\",\n",
                "    \"Approved Date\",\n",
                "    \"Submitted Date\",\n",
                "    \"Cancelled Date\",\n",
                "    \"Project Name\",\n",
                "    \"Product\",\n",
                "    \"Domain\",\n",
                "    \"Customer\",\n",
                "]\n",
                "\n",
                "def compute_order_src_hash(product: str, sub: pd.DataFrame) -> str:\n",
                "    \"\"\"Exact copy of compute_order_src_hash from influx_source.py\"\"\"\n",
                "    parts: List[Any] = [str(product or \"\")] \n",
                "    for c in HASH_COLUMNS:\n",
                "        try:\n",
                "            vals = list(sub[c])\n",
                "        except Exception:\n",
                "            vals = []\n",
                "        parts.append({c: [\"\" if v is None or pd.isna(v) else str(v) for v in vals]})\n",
                "    s = json.dumps(parts, sort_keys=True, separators=(\",\", \":\"))\n",
                "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
                "\n",
                "print(f\"Hash function uses {len(HASH_COLUMNS)} columns:\")\n",
                "for col in HASH_COLUMNS:\n",
                "    print(f\"  â€¢ {col}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# File paths\n",
                "BASE_DIR = Path('..')\n",
                "NOV_FILE = BASE_DIR / '11.25.WP Orders_25-11-2025_v01.xlsx'\n",
                "DEC_FILE = BASE_DIR / '12.04.WP Orders_04-12-2025_v01.xlsx'\n",
                "\n",
                "# Load data\n",
                "df_nov = pd.read_excel(NOV_FILE, sheet_name='WP_Overall_Order_Report')\n",
                "df_dec = pd.read_excel(DEC_FILE, sheet_name='WP_Overall_Order_Report')\n",
                "\n",
                "# Clean column names\n",
                "df_nov.columns = df_nov.columns.str.strip()\n",
                "df_dec.columns = df_dec.columns.str.strip()\n",
                "\n",
                "print(f\"November: {len(df_nov):,} orders\")\n",
                "print(f\"December: {len(df_dec):,} orders\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Key columns\n",
                "ORDER_ID_COL = 'WP Order ID'\n",
                "STATUS_COL = 'WP Order Status'\n",
                "PRODUCT_COL = 'Product'\n",
                "\n",
                "# Target products (matching delta apply registry exactly)\n",
                "# From config/product_project_registry.json\n",
                "TARGET_PRODUCT_PATTERNS = [\n",
                "    'flowone',\n",
                "    'flow one', \n",
                "    'niam',\n",
                "    'session border controller'\n",
                "]\n",
                "\n",
                "def is_target_product(product):\n",
                "    if pd.isna(product):\n",
                "        return False\n",
                "    product_lower = str(product).lower()\n",
                "    return any(t in product_lower for t in TARGET_PRODUCT_PATTERNS)\n",
                "\n",
                "# Filter to target products only (matching delta apply scope)\n",
                "df_nov_target = df_nov[df_nov[PRODUCT_COL].apply(is_target_product)].copy()\n",
                "df_dec_target = df_dec[df_dec[PRODUCT_COL].apply(is_target_product)].copy()\n",
                "\n",
                "print(f\"\\nðŸŽ¯ TARGET PRODUCTS:\")\n",
                "print(f\"November: {len(df_nov_target):,} orders\")\n",
                "print(f\"December: {len(df_dec_target):,} orders\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Product breakdown\n",
                "print(\"\\nðŸ“¦ December Product Breakdown:\")\n",
                "print(df_dec_target[PRODUCT_COL].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compute Hashes Per Order (Exact Delta Apply Method)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group by Order ID (like delta apply does)\n",
                "def compute_hashes_per_order(df):\n",
                "    \"\"\"Compute hash for each order, matching delta_apply_influx.py method.\"\"\"\n",
                "    order_hashes = {}\n",
                "    grouped = df.groupby(ORDER_ID_COL)\n",
                "    \n",
                "    for order_id, sub in grouped:\n",
                "        oid = str(order_id or \"\").strip()\n",
                "        if not oid:\n",
                "            continue\n",
                "        product = sub[PRODUCT_COL].iloc[0] if PRODUCT_COL in sub.columns else \"\"\n",
                "        order_hash = compute_order_src_hash(str(product or \"\"), sub)\n",
                "        order_hashes[oid] = {\n",
                "            'hash': order_hash,\n",
                "            'product': product,\n",
                "            'rows': len(sub)\n",
                "        }\n",
                "    \n",
                "    return order_hashes\n",
                "\n",
                "print(\"Computing hashes for November orders...\")\n",
                "nov_hashes = compute_hashes_per_order(df_nov_target)\n",
                "print(f\"  Computed {len(nov_hashes):,} order hashes\")\n",
                "\n",
                "print(\"\\nComputing hashes for December orders...\")\n",
                "dec_hashes = compute_hashes_per_order(df_dec_target)\n",
                "print(f\"  Computed {len(dec_hashes):,} order hashes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Compare Hashes (Delta Apply Method)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get order sets\n",
                "nov_order_ids = set(nov_hashes.keys())\n",
                "dec_order_ids = set(dec_hashes.keys())\n",
                "\n",
                "# Categorize\n",
                "new_orders = dec_order_ids - nov_order_ids  # In Dec but not Nov\n",
                "common_orders = nov_order_ids & dec_order_ids  # In both\n",
                "\n",
                "# Find changed orders (hash differs)\n",
                "changed_orders = set()\n",
                "unchanged_orders = set()\n",
                "\n",
                "for order_id in common_orders:\n",
                "    if nov_hashes[order_id]['hash'] != dec_hashes[order_id]['hash']:\n",
                "        changed_orders.add(order_id)\n",
                "    else:\n",
                "        unchanged_orders.add(order_id)\n",
                "\n",
                "print(f\"ðŸ“Š CHANGE DETECTION RESULTS\")\n",
                "print(f\"=\"*50)\n",
                "print(f\"November orders: {len(nov_order_ids):,}\")\n",
                "print(f\"December orders: {len(dec_order_ids):,}\")\n",
                "print(f\"\")\n",
                "print(f\"Common orders:   {len(common_orders):,}\")\n",
                "print(f\"  â†’ Changed:     {len(changed_orders):,}\")\n",
                "print(f\"  â†’ Unchanged:   {len(unchanged_orders):,}\")\n",
                "print(f\"\")\n",
                "print(f\"New orders:      {len(new_orders):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Delta Apply Compatible Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary matching delta apply output format\n",
                "total_dec_orders = len(dec_order_ids)\n",
                "changed_count = len(changed_orders)\n",
                "new_count = len(new_orders)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"        DELTA APPLY COMPATIBLE RESULTS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\")\n",
                "print(f\"   orders:   {total_dec_orders:>6,}  (unique order IDs in Dec)\")\n",
                "print(f\"   changed:  {changed_count:>6,}  (hash differs Novâ†’Dec)\")\n",
                "print(f\"   new:      {new_count:>6,}  (in Dec but not Nov)\")\n",
                "print(f\"\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Breakdown by product\n",
                "print(\"\\nðŸ“¦ CHANGED ORDERS BY PRODUCT:\")\n",
                "product_counts = {}\n",
                "for oid in changed_orders:\n",
                "    product = dec_hashes[oid]['product']\n",
                "    product_counts[product] = product_counts.get(product, 0) + 1\n",
                "\n",
                "for product, count in sorted(product_counts.items(), key=lambda x: -x[1]):\n",
                "    print(f\"  {product}: {count}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# New orders by product\n",
                "print(\"\\nðŸ†• NEW ORDERS BY PRODUCT:\")\n",
                "new_product_counts = {}\n",
                "for oid in new_orders:\n",
                "    product = dec_hashes[oid]['product']\n",
                "    new_product_counts[product] = new_product_counts.get(product, 0) + 1\n",
                "\n",
                "for product, count in sorted(new_product_counts.items(), key=lambda x: -x[1]):\n",
                "    print(f\"  {product}: {count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Status Changes Detail"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get status for changed orders\n",
                "df_nov_indexed = df_nov_target.drop_duplicates(ORDER_ID_COL).set_index(ORDER_ID_COL)\n",
                "df_dec_indexed = df_dec_target.drop_duplicates(ORDER_ID_COL).set_index(ORDER_ID_COL)\n",
                "\n",
                "status_changes = []\n",
                "for oid in changed_orders:\n",
                "    try:\n",
                "        nov_status = df_nov_indexed.loc[oid, STATUS_COL]\n",
                "        dec_status = df_dec_indexed.loc[oid, STATUS_COL]\n",
                "        product = df_dec_indexed.loc[oid, PRODUCT_COL]\n",
                "        \n",
                "        if nov_status != dec_status:\n",
                "            status_changes.append({\n",
                "                'Order ID': oid,\n",
                "                'Product': product,\n",
                "                'Nov_Status': nov_status,\n",
                "                'Dec_Status': dec_status,\n",
                "                'Transition': f\"{nov_status} â†’ {dec_status}\"\n",
                "            })\n",
                "    except:\n",
                "        pass\n",
                "\n",
                "df_status_changes = pd.DataFrame(status_changes)\n",
                "\n",
                "print(f\"ðŸ”„ STATUS CHANGES (within {len(changed_orders)} changed orders)\")\n",
                "print(f\"=\"*50)\n",
                "print(f\"Orders with status change: {len(df_status_changes):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Status transitions\n",
                "if len(df_status_changes) > 0:\n",
                "    print(\"\\nðŸ“Š Status Transitions:\")\n",
                "    print(df_status_changes['Transition'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Column-Level Change Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze which of the 17 hash columns changed\n",
                "column_changes = {col: 0 for col in HASH_COLUMNS}\n",
                "\n",
                "for oid in changed_orders:\n",
                "    try:\n",
                "        for col in HASH_COLUMNS:\n",
                "            if col in df_nov_indexed.columns and col in df_dec_indexed.columns:\n",
                "                nov_val = str(df_nov_indexed.loc[oid, col]) if oid in df_nov_indexed.index else ''\n",
                "                dec_val = str(df_dec_indexed.loc[oid, col]) if oid in df_dec_indexed.index else ''\n",
                "                if nov_val != dec_val:\n",
                "                    column_changes[col] += 1\n",
                "    except:\n",
                "        pass\n",
                "\n",
                "# Sort by count\n",
                "sorted_changes = sorted(column_changes.items(), key=lambda x: -x[1])\n",
                "\n",
                "print(f\"ðŸ“Š COLUMN CHANGES (within {len(changed_orders)} changed orders)\")\n",
                "print(f\"=\"*60)\n",
                "for col, count in sorted_changes:\n",
                "    if count > 0:\n",
                "        pct = count / len(changed_orders) * 100\n",
                "        is_status = 'Status' in col\n",
                "        is_date = 'Date' in col\n",
                "        marker = \"ðŸ”„\" if is_status else (\"ðŸ“…\" if is_date else \"  \")\n",
                "        print(f\"{marker} {col:<35} {count:>5,} ({pct:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Comparison Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*70)\n",
                "print(\"                        FINAL SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\")\n",
                "print(f\"Files: {NOV_FILE.name} â†’ {DEC_FILE.name}\")\n",
                "print(f\"\")\n",
                "print(f\"ðŸ“Š METRICS (using exact delta_apply hash function):\")\n",
                "print(f\"   Total orders (Dec):    {total_dec_orders:,}\")\n",
                "print(f\"   Changed orders:        {changed_count:,}\")\n",
                "print(f\"   New orders:            {new_count:,}\")\n",
                "print(f\"   Status changes:        {len(df_status_changes):,}\")\n",
                "print(f\"\")\n",
                "print(f\"ðŸ“¦ BY PRODUCT:\")\n",
                "for product in sorted(set(product_counts.keys()) | set(new_product_counts.keys())):\n",
                "    ch = product_counts.get(product, 0)\n",
                "    nw = new_product_counts.get(product, 0)\n",
                "    print(f\"   {product}: {ch} changed, {nw} new\")\n",
                "print(f\"\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Export"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
                "\n",
                "# Export changed orders list\n",
                "changed_list = [{'Order ID': oid, 'Product': dec_hashes[oid]['product']} for oid in changed_orders]\n",
                "pd.DataFrame(changed_list).to_excel(f'changed_orders_{timestamp}.xlsx', index=False)\n",
                "print(f\"âœ… changed_orders_{timestamp}.xlsx\")\n",
                "\n",
                "# Export new orders list  \n",
                "new_list = [{'Order ID': oid, 'Product': dec_hashes[oid]['product']} for oid in new_orders]\n",
                "pd.DataFrame(new_list).to_excel(f'new_orders_{timestamp}.xlsx', index=False)\n",
                "print(f\"âœ… new_orders_{timestamp}.xlsx\")\n",
                "\n",
                "# Export status changes\n",
                "if len(df_status_changes) > 0:\n",
                "    df_status_changes.to_excel(f'status_changes_{timestamp}.xlsx', index=False)\n",
                "    print(f\"âœ… status_changes_{timestamp}.xlsx\")\n",
                "\n",
                "print(f\"\\nâœ… Analysis complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}