{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "toc_visible": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83d\udcca SLA Analysis Dashboard\n",
                "\n",
                "**Purpose**: Track SLA compliance and identify work packages past their requested delivery date.\n",
                "\n",
                "## Key Metrics\n",
                "- SLA Breach % (orders past requested delivery date)\n",
                "- Days Overdue analysis\n",
                "- Breach % by Product\n",
                "- At-Risk Orders (approaching SLA deadline)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Install required packages\n",
                "!pip install pandas openpyxl plotly seaborn matplotlib -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime, timedelta\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.width', None)\n",
                "\n",
                "print(\"\u2705 Libraries loaded successfully!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# File path - update this to match your file location\n",
                "filename = r\"C:\\Users\\bmalaraju\\Documents\\WP-OP Agent\\JIRA-Agent\\11.25.WP Orders_25-11-2025_v01.xlsx\"\n",
                "print(f\"\ud83d\udcc1 Using file: {filename}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Load and prepare data\n",
                "df = pd.read_excel(filename, engine='openpyxl')\n",
                "\n",
                "# Display basic info\n",
                "print(f\"\ud83d\udcca Dataset loaded: {len(df):,} rows, {len(df.columns)} columns\")\n",
                "print(f\"\\n\ud83d\udcc5 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
                "\n",
                "# Show column names\n",
                "print(\"\\n\ud83d\udccb Available columns:\")\n",
                "for i, col in enumerate(df.columns, 1):\n",
                "    print(f\"  {i:2}. {col}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Column mapping - adjust if your columns have different names\n",
                "COLUMN_MAP = {\n",
                "    'requested_date': 'WP Requested Delivery Date',\n",
                "    'readiness_date': 'WP Readiness Date',\n",
                "    'status': 'WP Order Status',\n",
                "    'product': 'Product',\n",
                "    'customer': 'Customer',\n",
                "    'order_id': 'WP Order ID',\n",
                "    'wp_id': 'WP ID',\n",
                "    'wp_name': 'WP Name',\n",
                "    'quantity': 'WP Quantity',\n",
                "    'in_time_delivery': 'In-Time Delivery',\n",
                "    'added_date': 'Added Date',\n",
                "    'project_name': 'Project Name',\n",
                "    'domain': 'Domain'\n",
                "}\n",
                "\n",
                "# Validate columns exist\n",
                "missing_cols = [v for v in COLUMN_MAP.values() if v not in df.columns]\n",
                "if missing_cols:\n",
                "    print(f\"\u26a0\ufe0f Missing columns: {missing_cols}\")\n",
                "    print(\"\\nPlease update COLUMN_MAP with correct column names from your file.\")\n",
                "else:\n",
                "    print(\"\u2705 All required columns found!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Parse dates and prepare analysis dataframe\n",
                "analysis_df = df.copy()\n",
                "\n",
                "# Helper to strip timezone from dates\n",
                "def parse_date(series):\n",
                "    dt = pd.to_datetime(series, errors='coerce')\n",
                "    if dt.dt.tz is not None:\n",
                "        dt = dt.dt.tz_localize(None)\n",
                "    return dt\n",
                "\n",
                "# Parse requested delivery date\n",
                "analysis_df['target_date'] = parse_date(analysis_df[COLUMN_MAP['requested_date']])\n",
                "\n",
                "# Fallback to readiness date if requested date is missing\n",
                "if COLUMN_MAP['readiness_date'] in analysis_df.columns:\n",
                "    readiness = parse_date(analysis_df[COLUMN_MAP['readiness_date']])\n",
                "    analysis_df['target_date'] = analysis_df['target_date'].fillna(readiness)\n",
                "\n",
                "# Parse added date for trend analysis\n",
                "analysis_df['added_date'] = parse_date(analysis_df[COLUMN_MAP['added_date']])\n",
                "\n",
                "# Current date for SLA calculation\n",
                "TODAY = pd.Timestamp.now().normalize()\n",
                "\n",
                "# Terminal statuses (orders that are complete and shouldn't count as breached)\n",
                "TERMINAL_STATUSES = ['Approved', 'Cancelled', 'Rejected']\n",
                "\n",
                "# Calculate SLA metrics\n",
                "analysis_df['is_terminal'] = analysis_df[COLUMN_MAP['status']].isin(TERMINAL_STATUSES)\n",
                "analysis_df['has_target_date'] = analysis_df['target_date'].notna()\n",
                "analysis_df['is_past_due'] = (analysis_df['target_date'] < TODAY) & analysis_df['has_target_date']\n",
                "analysis_df['is_breached'] = analysis_df['is_past_due'] & ~analysis_df['is_terminal']\n",
                "analysis_df['days_overdue'] = np.where(\n",
                "    analysis_df['is_past_due'],\n",
                "    (TODAY - analysis_df['target_date']).dt.days,\n",
                "    0\n",
                ")\n",
                "\n",
                "# At-risk: due within 7 days, not terminal\n",
                "analysis_df['is_at_risk'] = (\n",
                "    (analysis_df['target_date'] >= TODAY) & \n",
                "    (analysis_df['target_date'] <= TODAY + timedelta(days=7)) &\n",
                "    ~analysis_df['is_terminal'] &\n",
                "    analysis_df['has_target_date']\n",
                ")\n",
                "\n",
                "print(f\"\u2705 Data prepared successfully!\")\n",
                "print(f\"\\n\ud83d\udcc5 Analysis date: {TODAY.strftime('%Y-%m-%d')}\")\n",
                "print(f\"\ud83d\udcca Orders with target dates: {analysis_df['has_target_date'].sum():,}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Overall SLA Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Calculate overall metrics\n",
                "total_orders = len(analysis_df)\n",
                "orders_with_date = analysis_df['has_target_date'].sum()\n",
                "active_orders = (~analysis_df['is_terminal'] & analysis_df['has_target_date']).sum()\n",
                "breached_orders = analysis_df['is_breached'].sum()\n",
                "at_risk_orders = analysis_df['is_at_risk'].sum()\n",
                "compliant_active = active_orders - breached_orders - at_risk_orders\n",
                "\n",
                "# Percentages\n",
                "breach_pct = (breached_orders / active_orders * 100) if active_orders > 0 else 0\n",
                "at_risk_pct = (at_risk_orders / active_orders * 100) if active_orders > 0 else 0\n",
                "compliant_pct = 100 - breach_pct - at_risk_pct\n",
                "\n",
                "# Display summary\n",
                "print(\"=\"*60)\n",
                "print(\"\ud83d\udcca SLA SUMMARY REPORT\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\n\ud83d\udccb Total Orders:           {total_orders:,}\")\n",
                "print(f\"\ud83d\udcc5 With Target Date:        {orders_with_date:,}\")\n",
                "print(f\"\ud83d\udd04 Active (Non-Terminal):   {active_orders:,}\")\n",
                "print(f\"\\n\ud83d\udea8 BREACHED (Past SLA):     {breached_orders:,} ({breach_pct:.1f}%)\")\n",
                "print(f\"\u26a0\ufe0f  AT RISK (Due \u22647 days):  {at_risk_orders:,} ({at_risk_pct:.1f}%)\")\n",
                "print(f\"\u2705 COMPLIANT:               {compliant_active:,} ({compliant_pct:.1f}%)\")\n",
                "print(\"=\"*60)"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# SLA Compliance Pie Chart\n",
                "labels = ['\ud83d\udea8 Breached', '\u26a0\ufe0f At Risk', '\u2705 Compliant']\n",
                "values = [breached_orders, at_risk_orders, compliant_active]\n",
                "colors = ['#FF6B6B', '#FFE66D', '#4ECDC4']\n",
                "\n",
                "fig = go.Figure(data=[go.Pie(\n",
                "    labels=labels,\n",
                "    values=values,\n",
                "    hole=0.4,\n",
                "    marker_colors=colors,\n",
                "    textinfo='percent+value',\n",
                "    textfont_size=14,\n",
                "    hovertemplate='%{label}<br>Orders: %{value}<br>Percentage: %{percent}<extra></extra>'\n",
                ")])\n",
                "\n",
                "fig.update_layout(\n",
                "    title={\n",
                "        'text': 'SLA Compliance Overview',\n",
                "        'x': 0.5,\n",
                "        'font': {'size': 20}\n",
                "    },\n",
                "    annotations=[{\n",
                "        'text': f'{compliant_pct:.0f}%<br>Compliant',\n",
                "        'x': 0.5, 'y': 0.5,\n",
                "        'font_size': 16,\n",
                "        'showarrow': False\n",
                "    }],\n",
                "    showlegend=True,\n",
                "    legend={'orientation': 'h', 'y': -0.1},\n",
                "    height=500\n",
                ")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# SLA Compliance Gauge\n",
                "fig = go.Figure(go.Indicator(\n",
                "    mode=\"gauge+number+delta\",\n",
                "    value=compliant_pct,\n",
                "    domain={'x': [0, 1], 'y': [0, 1]},\n",
                "    title={'text': \"SLA Compliance Rate\", 'font': {'size': 24}},\n",
                "    delta={'reference': 85, 'increasing': {'color': \"green\"}},\n",
                "    gauge={\n",
                "        'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': \"darkblue\"},\n",
                "        'bar': {'color': \"#4ECDC4\"},\n",
                "        'bgcolor': \"white\",\n",
                "        'borderwidth': 2,\n",
                "        'bordercolor': \"gray\",\n",
                "        'steps': [\n",
                "            {'range': [0, 50], 'color': '#FF6B6B'},\n",
                "            {'range': [50, 75], 'color': '#FFE66D'},\n",
                "            {'range': [75, 100], 'color': '#C8E6C9'}\n",
                "        ],\n",
                "        'threshold': {\n",
                "            'line': {'color': \"red\", 'width': 4},\n",
                "            'thickness': 0.75,\n",
                "            'value': 85\n",
                "        }\n",
                "    }\n",
                "))\n",
                "\n",
                "fig.update_layout(height=400)\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. SLA Breach Analysis by Product"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Calculate breach rate by product\n",
                "product_col = COLUMN_MAP['product']\n",
                "\n",
                "product_stats = analysis_df[analysis_df['has_target_date'] & ~analysis_df['is_terminal']].groupby(product_col).agg(\n",
                "    total_active=('is_breached', 'count'),\n",
                "    breached=('is_breached', 'sum'),\n",
                "    at_risk=('is_at_risk', 'sum'),\n",
                "    avg_days_overdue=('days_overdue', lambda x: x[x > 0].mean() if (x > 0).any() else 0)\n",
                ").reset_index()\n",
                "\n",
                "product_stats['breach_pct'] = (product_stats['breached'] / product_stats['total_active'] * 100).round(1)\n",
                "product_stats['at_risk_pct'] = (product_stats['at_risk'] / product_stats['total_active'] * 100).round(1)\n",
                "product_stats = product_stats.sort_values('breach_pct', ascending=False)\n",
                "\n",
                "# Display top products by breach rate\n",
                "print(\"\\n\ud83d\udea8 SLA BREACH % BY PRODUCT (Top 15)\")\n",
                "print(\"=\"*80)\n",
                "display_df = product_stats.head(15)[[\n",
                "    product_col, 'total_active', 'breached', 'breach_pct', 'at_risk', 'avg_days_overdue'\n",
                "]].copy()\n",
                "display_df.columns = ['Product', 'Active Orders', 'Breached', 'Breach %', 'At Risk', 'Avg Days Overdue']\n",
                "display_df['Avg Days Overdue'] = display_df['Avg Days Overdue'].round(0).astype(int)\n",
                "print(display_df.to_string(index=False))"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Bar chart: Breach % by Product\n",
                "top_products = product_stats.head(15)\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    y=top_products[product_col],\n",
                "    x=top_products['breach_pct'],\n",
                "    orientation='h',\n",
                "    name='Breach %',\n",
                "    marker_color='#FF6B6B',\n",
                "    text=top_products['breach_pct'].apply(lambda x: f'{x:.1f}%'),\n",
                "    textposition='outside',\n",
                "    hovertemplate='%{y}<br>Breach Rate: %{x:.1f}%<extra></extra>'\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'SLA Breach Rate by Product', 'x': 0.5, 'font': {'size': 20}},\n",
                "    xaxis_title='Breach %',\n",
                "    yaxis_title='Product',\n",
                "    yaxis={'categoryorder': 'total ascending'},\n",
                "    height=600,\n",
                "    margin={'l': 200}\n",
                ")\n",
                "\n",
                "# Add target line at 15%\n",
                "fig.add_vline(x=15, line_dash=\"dash\", line_color=\"green\", \n",
                "              annotation_text=\"Target: 15%\", annotation_position=\"top\")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Stacked bar: Compliant vs Breached vs At-Risk by Product\n",
                "top_products['compliant'] = top_products['total_active'] - top_products['breached'] - top_products['at_risk']\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    y=top_products[product_col],\n",
                "    x=top_products['compliant'],\n",
                "    name='\u2705 Compliant',\n",
                "    orientation='h',\n",
                "    marker_color='#4ECDC4'\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    y=top_products[product_col],\n",
                "    x=top_products['at_risk'],\n",
                "    name='\u26a0\ufe0f At Risk',\n",
                "    orientation='h',\n",
                "    marker_color='#FFE66D'\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    y=top_products[product_col],\n",
                "    x=top_products['breached'],\n",
                "    name='\ud83d\udea8 Breached',\n",
                "    orientation='h',\n",
                "    marker_color='#FF6B6B'\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'SLA Status Distribution by Product', 'x': 0.5, 'font': {'size': 20}},\n",
                "    barmode='stack',\n",
                "    xaxis_title='Number of Orders',\n",
                "    yaxis_title='Product',\n",
                "    yaxis={'categoryorder': 'total ascending'},\n",
                "    height=600,\n",
                "    margin={'l': 200},\n",
                "    legend={'orientation': 'h', 'y': 1.1}\n",
                ")\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. SLA Analysis by Customer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Heatmap: Breach count by Product x Customer\n",
                "customer_col = COLUMN_MAP['customer']\n",
                "\n",
                "# Get top products and customers by breach count\n",
                "top_n = 10\n",
                "top_breach_products = product_stats.head(top_n)[product_col].tolist()\n",
                "\n",
                "customer_stats = analysis_df[analysis_df['is_breached']].groupby(customer_col).size()\n",
                "top_customers = customer_stats.nlargest(top_n).index.tolist()\n",
                "\n",
                "# Filter data for heatmap\n",
                "heatmap_data = analysis_df[\n",
                "    analysis_df[product_col].isin(top_breach_products) & \n",
                "    analysis_df[customer_col].isin(top_customers) &\n",
                "    analysis_df['is_breached']\n",
                "].groupby([product_col, customer_col]).size().unstack(fill_value=0)\n",
                "\n",
                "if not heatmap_data.empty:\n",
                "    fig = px.imshow(\n",
                "        heatmap_data,\n",
                "        labels=dict(x=\"Customer\", y=\"Product\", color=\"Breach Count\"),\n",
                "        x=heatmap_data.columns,\n",
                "        y=heatmap_data.index,\n",
                "        color_continuous_scale='Reds',\n",
                "        title='SLA Breaches Heatmap: Product \u00d7 Customer'\n",
                "    )\n",
                "    \n",
                "    fig.update_layout(\n",
                "        height=500,\n",
                "        xaxis_tickangle=-45\n",
                "    )\n",
                "    \n",
                "    fig.show()\n",
                "else:\n",
                "    print(\"No breach data available for heatmap visualization.\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. SLA Trends Over Time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Weekly SLA breach trend\n",
                "trend_df = analysis_df[analysis_df['added_date'].notna()].copy()\n",
                "trend_df['week'] = trend_df['added_date'].dt.to_period('W').dt.start_time\n",
                "\n",
                "weekly_stats = trend_df.groupby('week').agg(\n",
                "    total=('is_breached', 'count'),\n",
                "    breached=('is_breached', 'sum')\n",
                ").reset_index()\n",
                "\n",
                "weekly_stats['breach_pct'] = (weekly_stats['breached'] / weekly_stats['total'] * 100).round(1)\n",
                "\n",
                "# Filter to recent 12 weeks\n",
                "weekly_stats = weekly_stats.tail(12)\n",
                "\n",
                "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
                "\n",
                "fig.add_trace(\n",
                "    go.Bar(x=weekly_stats['week'], y=weekly_stats['breached'], name='Breached Orders',\n",
                "           marker_color='#FF6B6B'),\n",
                "    secondary_y=False\n",
                ")\n",
                "\n",
                "fig.add_trace(\n",
                "    go.Scatter(x=weekly_stats['week'], y=weekly_stats['breach_pct'], name='Breach %',\n",
                "               mode='lines+markers', line=dict(color='#2C3E50', width=3)),\n",
                "    secondary_y=True\n",
                ")\n",
                "\n",
                "fig.update_layout(\n",
                "    title={'text': 'Weekly SLA Breach Trend', 'x': 0.5, 'font': {'size': 20}},\n",
                "    xaxis_title='Week',\n",
                "    height=450,\n",
                "    legend={'orientation': 'h', 'y': 1.1}\n",
                ")\n",
                "\n",
                "fig.update_yaxes(title_text=\"Breached Orders\", secondary_y=False)\n",
                "fig.update_yaxes(title_text=\"Breach %\", secondary_y=True)\n",
                "\n",
                "fig.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Days Overdue Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Days overdue distribution\n",
                "overdue_df = analysis_df[analysis_df['is_breached'] & (analysis_df['days_overdue'] > 0)].copy()\n",
                "\n",
                "if len(overdue_df) > 0:\n",
                "    # Bucket the days overdue\n",
                "    bins = [0, 7, 14, 30, 60, 90, float('inf')]\n",
                "    labels = ['1-7 days', '8-14 days', '15-30 days', '31-60 days', '61-90 days', '90+ days']\n",
                "    overdue_df['overdue_bucket'] = pd.cut(overdue_df['days_overdue'], bins=bins, labels=labels)\n",
                "    \n",
                "    bucket_counts = overdue_df['overdue_bucket'].value_counts().sort_index()\n",
                "    \n",
                "    colors = ['#FFE66D', '#FFD93D', '#FF9F1C', '#FF6B35', '#FF4444', '#8B0000']\n",
                "    \n",
                "    fig = go.Figure(data=[go.Bar(\n",
                "        x=bucket_counts.index.astype(str),\n",
                "        y=bucket_counts.values,\n",
                "        marker_color=colors,\n",
                "        text=bucket_counts.values,\n",
                "        textposition='outside'\n",
                "    )])\n",
                "    \n",
                "    fig.update_layout(\n",
                "        title={'text': 'Distribution of Days Overdue', 'x': 0.5, 'font': {'size': 20}},\n",
                "        xaxis_title='Days Overdue Category',\n",
                "        yaxis_title='Number of Orders',\n",
                "        height=400\n",
                "    )\n",
                "    \n",
                "    fig.show()\n",
                "    \n",
                "    # Summary stats\n",
                "    print(\"\\n\ud83d\udcca Days Overdue Statistics:\")\n",
                "    print(f\"   Mean:   {overdue_df['days_overdue'].mean():.1f} days\")\n",
                "    print(f\"   Median: {overdue_df['days_overdue'].median():.1f} days\")\n",
                "    print(f\"   Max:    {overdue_df['days_overdue'].max():.0f} days\")\n",
                "else:\n",
                "    print(\"\u2705 No overdue orders found!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Most Critical Orders (Top 20 Overdue)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Top 20 most overdue orders\n",
                "critical_orders = analysis_df[\n",
                "    analysis_df['is_breached'] & (analysis_df['days_overdue'] > 0)\n",
                "].nlargest(20, 'days_overdue')[[\n",
                "    COLUMN_MAP['order_id'],\n",
                "    COLUMN_MAP['product'],\n",
                "    COLUMN_MAP['customer'],\n",
                "    COLUMN_MAP['status'],\n",
                "    'target_date',\n",
                "    'days_overdue'\n",
                "]].copy()\n",
                "\n",
                "critical_orders.columns = ['Order ID', 'Product', 'Customer', 'Status', 'Target Date', 'Days Overdue']\n",
                "critical_orders['Target Date'] = critical_orders['Target Date'].dt.strftime('%Y-%m-%d')\n",
                "\n",
                "print(\"\\n\ud83d\udea8 TOP 20 MOST CRITICAL OVERDUE ORDERS\")\n",
                "print(\"=\"*100)\n",
                "print(critical_orders.to_string(index=False))"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. At-Risk Orders (Due Within 7 Days)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# At-risk orders list\n",
                "at_risk_df = analysis_df[analysis_df['is_at_risk']][[\n",
                "    COLUMN_MAP['order_id'],\n",
                "    COLUMN_MAP['product'],\n",
                "    COLUMN_MAP['customer'],\n",
                "    COLUMN_MAP['status'],\n",
                "    'target_date'\n",
                "]].copy()\n",
                "\n",
                "at_risk_df['days_until_due'] = (at_risk_df['target_date'] - TODAY).dt.days\n",
                "at_risk_df = at_risk_df.sort_values('days_until_due')\n",
                "at_risk_df.columns = ['Order ID', 'Product', 'Customer', 'Status', 'Target Date', 'Days Until Due']\n",
                "at_risk_df['Target Date'] = pd.to_datetime(at_risk_df['Target Date']).dt.strftime('%Y-%m-%d')\n",
                "\n",
                "print(f\"\\n\u26a0\ufe0f AT-RISK ORDERS (Due within 7 days): {len(at_risk_df)} orders\")\n",
                "print(\"=\"*100)\n",
                "if len(at_risk_df) > 0:\n",
                "    print(at_risk_df.head(20).to_string(index=False))\n",
                "    if len(at_risk_df) > 20:\n",
                "        print(f\"\\n... and {len(at_risk_df) - 20} more orders\")\n",
                "else:\n",
                "    print(\"\u2705 No at-risk orders found!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Export Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Export summary to Excel\n",
                "from datetime import datetime\n",
                "\n",
                "export_filename = f\"sla_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
                "\n",
                "with pd.ExcelWriter(export_filename, engine='openpyxl') as writer:\n",
                "    # Summary sheet\n",
                "    summary_data = pd.DataFrame({\n",
                "        'Metric': ['Total Orders', 'Active Orders', 'Breached', 'At Risk', 'Compliant', \n",
                "                   'Breach %', 'At Risk %', 'Compliance %'],\n",
                "        'Value': [total_orders, active_orders, breached_orders, at_risk_orders, compliant_active,\n",
                "                  f'{breach_pct:.1f}%', f'{at_risk_pct:.1f}%', f'{compliant_pct:.1f}%']\n",
                "    })\n",
                "    summary_data.to_excel(writer, sheet_name='Summary', index=False)\n",
                "    \n",
                "    # Product breakdown\n",
                "    product_stats.to_excel(writer, sheet_name='By Product', index=False)\n",
                "    \n",
                "    # Critical orders\n",
                "    critical_orders.to_excel(writer, sheet_name='Critical Orders', index=False)\n",
                "    \n",
                "    # At-risk orders\n",
                "    at_risk_df.to_excel(writer, sheet_name='At Risk Orders', index=False)\n",
                "\n",
                "print(f\"\\n\u2705 Results exported to: {export_filename}\")\n",
                "\n",
                "# Download the file\n",
                "# files.download() - uncomment if using Colab\n",
                "# files.download(export_filename)"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## \ud83d\udccb Summary\n",
                "\n",
                "This notebook analyzed SLA compliance across your work package orders:\n",
                "\n",
                "| Metric | Description |\n",
                "|--------|-------------|\n",
                "| **SLA Breach** | Orders past their requested delivery date (non-terminal status) |\n",
                "| **At Risk** | Orders due within 7 days (non-terminal status) |\n",
                "| **Compliant** | Active orders with target date in the future |\n",
                "| **Days Overdue** | Calendar days past the target date |\n",
                "\n",
                "### Key Actions\n",
                "1. Review the **Critical Orders** list for immediate attention\n",
                "2. Focus on **At-Risk Orders** to prevent future breaches\n",
                "3. Investigate products with high breach rates\n",
                "4. Use the exported Excel file for detailed follow-up"
            ]
        }
    ]
}